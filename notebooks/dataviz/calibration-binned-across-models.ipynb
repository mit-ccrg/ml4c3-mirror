{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "from sklearn.metrics import auc, roc_curve, brier_score_loss\n",
    "from sklearn.calibration import calibration_curve\n",
    "from scipy import stats\n",
    "%matplotlib inline\n",
    "\n",
    "bootstraps = 10\n",
    "n_bins = 10\n",
    "plot_dir = os.path.expanduser(\"~/dropbox/sts-ecg/figures-and-tables\")\n",
    "prediction_dir = os.path.expanduser(\"~/dropbox/sts-ecg/predictions\")\n",
    "label = \"sts_death\"\n",
    "models = [\"v30\", \"deep-sts-preop-v13-swish\", \"ecgnet-stsnet\"]\n",
    "titles = [\"ECGNet\", \"STSNet\", \"ECGNet STSNet\"]\n",
    "verbose_titles = [\"ECGNet v30\", \"STSNet v13 swish\", \"ECGNet STSNet\"]\n",
    "min_max_scale=False\n",
    "\n",
    "os.makedirs(plot_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(models: str, label: str, prediction_dir: str, min_max_scale: bool):\n",
    "    \"\"\"Get predictions as a dictionary of list of tuples\"\"\"\n",
    "    data = defaultdict(list)\n",
    "    y_hat_min = 1\n",
    "    y_hat_max = 0\n",
    "    for model in models:\n",
    "        for bootstrap in range(bootstraps):\n",
    "            fpath = os.path.join(prediction_dir, model, str(bootstrap), \"predictions_test.csv\")\n",
    "            df = pd.read_csv(fpath)\n",
    "            y = df[f'{label}_{label}_actual']\n",
    "            y_hat = df[f'{label}_{label}_predicted']\n",
    "            if min_max_scale:\n",
    "                y_hat = (y_hat - y_hat.min()) / (y_hat.max() - y_hat.min())\n",
    "            cur_min = y_hat.min()\n",
    "            cur_max = y_hat.max()\n",
    "            if cur_min < y_hat_min:\n",
    "                y_hat_min = cur_min\n",
    "            if cur_max > y_hat_max:\n",
    "                y_hat_max = cur_max\n",
    "            data[model].append((y, y_hat))\n",
    "    return data, y_hat_min, y_hat_max\n",
    "data, x_min, x_max = get_predictions(models=models, label=label, prediction_dir=prediction_dir, min_max_scale=min_max_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_calibrations_across_bootstraps(data, plot_title, file_title, x_min, x_max, n_bins, plot_dir):\n",
    "    sns.set(style=\"white\", palette=\"muted\", color_codes=True)\n",
    "    sns.set_context(\"talk\")\n",
    "\n",
    "    bins = np.linspace(x_min, x_max, n_bins + 1)\n",
    "    bins[0] -= 0.0001\n",
    "    bins[-1] += 0.0001\n",
    "\n",
    "    brier_scores = np.zeros((bootstraps,))\n",
    "    died_counts = np.zeros((bootstraps, n_bins))\n",
    "    pred_probs = np.zeros((bootstraps, n_bins))\n",
    "    true_probs = np.zeros((bootstraps, n_bins))\n",
    "    bin_counts = np.zeros((bootstraps, n_bins))\n",
    "    for bootstrap, (y, y_hat) in enumerate(data):\n",
    "        brier_scores[bootstrap] = brier_score_loss(y, y_hat, pos_label=1)\n",
    "        \n",
    "        # bin by predicted probabilities\n",
    "        bin_mask = pd.cut(y_hat, bins)\n",
    "        y_hat_bin_sums = y_hat.groupby(bin_mask).sum()\n",
    "        y_bin_sums = y.groupby(bin_mask).sum()\n",
    "        bin_count = y.groupby(bin_mask).count()\n",
    "\n",
    "        died_counts[bootstrap] = y_bin_sums\n",
    "        pred_probs[bootstrap] = y_hat_bin_sums / bin_count\n",
    "        true_probs[bootstrap] = y_bin_sums / bin_count\n",
    "        bin_counts[bootstrap] = bin_count\n",
    "\n",
    "    mean_brier_score = brier_scores.mean()\n",
    "    std_brier_score = brier_scores.std()\n",
    "\n",
    "    mean_pred_prob = np.nanmean(pred_probs, axis=0)\n",
    "    std_pred_prob = np.nanstd(pred_probs, axis=0)\n",
    "    sem_pred_prob = stats.sem(pred_probs, axis=0, nan_policy='omit')\n",
    "\n",
    "    mean_true_prob = np.nanmean(true_probs, axis=0)\n",
    "    std_true_prob = np.nanstd(true_probs, axis=0)\n",
    "    sem_true_prob = stats.sem(true_probs, axis=0, nan_policy='omit')\n",
    "\n",
    "    mean_bin_count = np.nanmean(bin_counts, axis=0)\n",
    "    O1bs = np.nanmean(died_counts, axis=0)\n",
    "    O0bs = np.nanmean(bin_counts - died_counts, axis=0)\n",
    "    E1bs = mean_pred_prob * mean_bin_count\n",
    "    E0bs = (1 - mean_pred_prob) * mean_bin_count\n",
    "\n",
    "    # only use bins that have \n",
    "    E1bs = E1bs[~np.isnan(E1bs)]\n",
    "    dof = len(E1bs)\n",
    "\n",
    "    HL_score = 0\n",
    "    for O1b, O0b, E1b, E0b in zip(O1bs, O0bs, E1bs, E0bs):\n",
    "        HL_score += (O1b - E1b) ** 2 / E1b + (O0b - E0b) ** 2 / E0b\n",
    "    p = 1 - stats.chi2.cdf(HL_score, max(0, dof - 2))\n",
    "\n",
    "    lim = [-0.1, 1.1]\n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "    ax.plot(lim, lim, linestyle='--', lw=2, color='r', alpha=.8)\n",
    "\n",
    "    ax.errorbar(\n",
    "        x=mean_pred_prob,\n",
    "        y=mean_true_prob,\n",
    "        xerr=sem_pred_prob,\n",
    "        yerr=sem_true_prob,\n",
    "        fmt=\".\",\n",
    "        ecolor=\"cornflowerblue\",\n",
    "        elinewidth=2.5,\n",
    "        capsize=2,\n",
    "    )\n",
    "    ticks = np.arange(0, 1.1, 0.2)\n",
    "    ax.set(\n",
    "        xticks=ticks,\n",
    "        yticks=ticks,\n",
    "        xlim=lim,\n",
    "        ylim=lim,\n",
    "        # title=f\"{plot_title}: Brier score = {mean_brier_score:0.3f} $\\pm$ {std_brier_score:0.3f}\",\n",
    "        title=f\"{plot_title}: HL score = {HL_score:.1f}, p = {p:.2f}\",\n",
    "        xlabel=\"Predicted\",\n",
    "        ylabel=\"Actual\",\n",
    "    )\n",
    "    ax.xaxis.set_major_formatter(FormatStrFormatter('%.2f'))\n",
    "    ax.yaxis.set_major_formatter(FormatStrFormatter('%.2f'))\n",
    "    ax.grid()\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    fpath = os.path.join(plot_dir, f'calibration-{file_title.replace(\" \", \"-\")}.png')\n",
    "    plt.savefig(fpath)\n",
    "    print(f\"Saved {fpath}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for title, verbose_title, (model, _data) in zip(titles, verbose_titles, data.items()):\n",
    "    plot_calibrations_across_bootstraps(\n",
    "        data=_data,\n",
    "        plot_title=title,\n",
    "        file_title=verbose_title,\n",
    "        x_min=x_min,\n",
    "        x_max=x_max,\n",
    "        n_bins=n_bins,\n",
    "        plot_dir=plot_dir,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
